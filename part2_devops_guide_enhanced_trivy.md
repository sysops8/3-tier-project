# üöÄ Production-Ready –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ E-Commerce –Ω–∞ Proxmox v2.0

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-K3s-326CE5?logo=kubernetes)](https://k3s.io/)
[![ArgoCD](https://img.shields.io/badge/GitOps-ArgoCD-EF7B4D?logo=argo)](https://argo-cd.readthedocs.io/)
[![Security](https://img.shields.io/badge/Security-Vault-000000?logo=vault)](https://www.vaultproject.io/)
[![Backup](https://img.shields.io/badge/Backup-Velero-00ADD8?logo=vmware)](https://velero.io/)

> **–ù–û–í–û–ï –≤ v2.0:** Security Enhancements + Automated Backups + Canary Deployments

---

## üìë –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- [–ß—Ç–æ –Ω–æ–≤–æ–≥–æ –≤ v2.0](#-—á—Ç–æ-–Ω–æ–≤–æ–≥–æ-–≤-v20)
- [–û–±–∑–æ—Ä](#-–æ–±–∑–æ—Ä)
- [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
- [–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫](#-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π-—Å—Ç–µ–∫)
- [–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã](#-—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏-–∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã)
- [–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è](#-–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)
- [–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ](#-—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ-–ø–æ-—É—Å—Ç–∞–Ω–æ–≤–∫–µ)
  - [–ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (Steps 1-9)](#–±–∞–∑–æ–≤–∞—è-–∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
  - [CI/CD (Jenkins)](#10-cicd-jenkins)
  - [–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (Prometheus Stack)](#11-–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥-prometheus-stack)
  - [–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (ELK Stack)](#12-–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ-elk-stack)
  - [GitOps (ArgoCD)](#13-gitops-argocd)
  - [üÜï Security Layer (Vault + Trivy)](#14-–Ω–æ–≤–æ–µ-security-layer-vault--trivy)
  - [üÜï Backup & DR (Velero)](#15-–Ω–æ–≤–æ–µ-backup--dr-velero)
  - [üÜï Canary Deployments (Argo Rollouts)](#16-–Ω–æ–≤–æ–µ-canary-deployments-argo-rollouts)
  - [–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è](#17-—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è)
- [CI/CD –ø–∞–π–ø–ª–∞–π–Ω v2.0](#-cicd-–ø–∞–π–ø–ª–∞–π–Ω-v20)
- [Disaster Recovery –ø—Ä–æ—Ü–µ–¥—É—Ä—ã](#-disaster-recovery-–ø—Ä–æ—Ü–µ–¥—É—Ä—ã)
- [–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ–ø–æ–≤–µ—â–µ–Ω–∏—è](#-–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥-–∏-–æ–ø–æ–≤–µ—â–µ–Ω–∏—è)
- [–£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫](#-—É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ-–Ω–µ–ø–æ–ª–∞–¥–æ–∫)

---

## üÜï –ß—Ç–æ –Ω–æ–≤–æ–≥–æ –≤ v2.0

### ‚ú® –û—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –£–ª—É—á—à–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |
|-----------|-----------|----------|
| üîí **Security** | HashiCorp Vault | –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–∞–º–∏ |
| üîí **Security** | Trivy Scanner | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–∑–æ–≤ –≤ CI |
| üîí **Security** | Network Policies | –ú–∏–∫—Ä–æ—Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Ç—Ä–∞—Ñ–∏–∫–∞ –º–µ–∂–¥—É –ø–æ–¥–∞–º–∏ |
| üíæ **Backup** | Velero | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ backup –∫–ª–∞—Å—Ç–µ—Ä–∞ –∫–∞–∂–¥—ã–µ 24—á |
| üíæ **Backup** | PostgreSQL Snapshots | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ backup –ë–î –∫–∞–∂–¥—ã–µ 3—á |
| üíæ **Backup** | MinIO Integration | –•—Ä–∞–Ω–µ–Ω–∏–µ backup –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º S3 |
| üöÄ **Deployments** | Argo Rollouts | Canary —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º rollback |
| üöÄ **Deployments** | Progressive Delivery | –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ —Ä–∞—Å–∫–∞—Ç—ã–≤–∞–Ω–∏–µ: 20% ‚Üí 40% ‚Üí 60% ‚Üí 80% ‚Üí 100% |
| üöÄ **Deployments** | Analysis Templates | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç—Ä–∏–∫ –ø–µ—Ä–µ–¥ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º |
| ‚ö° **Performance** | HPA | –ê–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ CPU/Memory |
| ‚ö° **Performance** | PDB | –ó–∞—â–∏—Ç–∞ –æ—Ç —Å–ª—É—á–∞–π–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø–æ–¥–æ–≤ |
| ‚ö° **Performance** | Resource Limits | –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–∏–º–∏—Ç—ã —Ä–µ—Å—É—Ä—Å–æ–≤ |

---

## üéØ –û–±–∑–æ—Ä

–ü–æ–ª–Ω–∞—è production-ready DevOps –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å **enterprise-grade security**, **automated disaster recovery** –∏ **zero-downtime deployments**.

### –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ v2.0

#### –ë–∞–∑–æ–≤—ã–µ (–∏–∑ v1.0)
- ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π CI/CD - Jenkins + ArgoCD GitOps
- ‚úÖ –í—ã—Å–æ–∫–∞—è –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å - –ú–Ω–æ–≥–æ—É–∑–ª–æ–≤–æ–π K3s –∫–ª–∞—Å—Ç–µ—Ä
- ‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ - Prometheus + Grafana + AlertManager
- ‚úÖ –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ - ELK Stack
- ‚úÖ –ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ - Longhorn
- ‚úÖ LoadBalancer - MetalLB –¥–ª—è bare-metal
- ‚úÖ –í–Ω–µ—à–Ω–∏–π –¥–æ—Å—Ç—É–ø - Cloudflare Tunnel

#### –ù–æ–≤—ã–µ (v2.0)
- üÜï **Zero-Trust Security** - Vault + Network Policies + Image Scanning
- üÜï **Automated Backups** - Velero (–∫–ª–∞—Å—Ç–µ—Ä) + CronJob (–ë–î) –∫–∞–∂–¥—ã–µ 3-24—á
- üÜï **Disaster Recovery** - RTO < 30 –º–∏–Ω—É—Ç, RPO < 3 —á–∞—Å–∞
- üÜï **Progressive Delivery** - Canary deployments —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
- üÜï **Self-Healing** - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π rollback –ø—Ä–∏ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫
- üÜï **Horizontal Autoscaling** - HPA –Ω–∞ –æ—Å–Ω–æ–≤–µ CPU/Memory/Custom –º–µ—Ç—Ä–∏–∫

---

## üéØ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ v2.0

```
–ò–Ω—Ç–µ—Ä–Ω–µ—Ç (—Å–µ—Ä—ã–π IP)
    ‚Üì
Cloudflare Tunnel (cf-tunnel VM)
    ‚Üì [NAT —à–ª—é–∑]
    ‚Üì
MetalLB LoadBalancer (192.168.100.100)
    ‚Üì
Traefik Ingress –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   K3s –∫–ª–∞—Å—Ç–µ—Ä (192.168.100.0/24)                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  ‚îÇ Master   ‚îÇ Worker-1 ‚îÇ Worker-2 ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ 4C/8GB   ‚îÇ 4C/10GB  ‚îÇ 4C/10GB  ‚îÇ             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  üÜï Security Layer:                              ‚îÇ
‚îÇ  - Vault (—Å–µ–∫—Ä–µ—Ç—ã)                               ‚îÇ
‚îÇ  - Network Policies (–∏–∑–æ–ª—è—Ü–∏—è)                   ‚îÇ
‚îÇ  - Trivy (—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–∑–æ–≤)                  ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  üÜï Backup Layer:                                ‚îÇ
‚îÇ  - Velero (backup –∫–ª–∞—Å—Ç–µ—Ä–∞ ‚Üí MinIO)              ‚îÇ
‚îÇ  - PostgreSQL CronJob (backup –ë–î ‚Üí PVC)          ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  üÜï Deployment Layer:                            ‚îÇ
‚îÇ  - Argo Rollouts (Canary deployments)            ‚îÇ
‚îÇ  - Analysis Templates (–∞–≤—Ç–æ–ø—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç—Ä–∏–∫)      ‚îÇ
‚îÇ  - HPA (–∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ)                     ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è:                                     ‚îÇ
‚îÇ  - EzyShop (E-commerce) - Canary ready           ‚îÇ
‚îÇ  - ArgoCD (GitOps —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ)                 ‚îÇ
‚îÇ  - Prometheus/Grafana (–ú–µ—Ç—Ä–∏–∫–∏)                  ‚îÇ
‚îÇ  - Elasticsearch/Kibana (–õ–æ–≥–∏)                   ‚îÇ
‚îÇ  - AlertManager ‚Üí Slack                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì                    ‚Üì
Jenkins CI          MinIO S3
(192.168.100.101)   (192.168.100.20)
    ‚Üì                    ‚Üì
Trivy Scanner       Velero Backups
                    PostgreSQL Backups

–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã:
- BIND9 DNS (192.168.100.53)
- NAT —à–ª—é–∑ (192.168.100.50)
- MetalLB LoadBalancer (192.168.100.100)
- Jumphost (192.168.100.5)
```

---

## üõ†Ô∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ v2.0

### üÜï –ù–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

#### Security
- **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–∞–º–∏**: HashiCorp Vault
- **–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–∑–æ–≤**: Trivy
- **–°–µ—Ç–µ–≤–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**: Kubernetes Network Policies
- **Pod Security**: PodDisruptionBudget + SecurityContext

#### Backup & DR
- **–ö–ª–∞—Å—Ç–µ—Ä backup**: Velero 1.12+
- **–ë–î backup**: PostgreSQL CronJob
- **–•—Ä–∞–Ω–∏–ª–∏—â–µ backup**: MinIO S3
- **Retention**: 7 –¥–Ω–µ–π –¥–ª—è –ë–î, 30 –¥–Ω–µ–π –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞

#### Deployment
- **Progressive Delivery**: Argo Rollouts
- **Canary Analysis**: Prometheus-based metrics
- **Autoscaling**: Horizontal Pod Autoscaler (HPA)
- **Traffic Management**: TrafficRouting via Traefik

---

## üìä –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã

### –í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ –º–∞—à–∏–Ω—ã (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)

| Hostname | vCPU | RAM | –î–∏—Å–∫ | –°–µ—Ç—å | IP | –†–æ–ª—å |
|----------|------|-----|------|---------|-----|------|
| dns-server | 1 | 1GB | 10GB | vmbr0+vmbr1 | 10.0.10.53<br>192.168.100.53 | DNS —Å–µ—Ä–≤–µ—Ä (BIND9) |
| cf-tunnel | 1 | 1GB | 10GB | vmbr0+vmbr1 | 10.0.10.50<br>192.168.100.50 | NAT —à–ª—é–∑ + —Ç—É–Ω–Ω–µ–ª—å |
| k3s-master | 4 | 8GB | 60GB (SSD) | vmbr1 | 192.168.100.10 | K3s Control Plane |
| k3s-worker-1 | 4 | 10GB | 80GB (SSD) | vmbr1 | 192.168.100.11 | K3s —Ä–∞–±–æ—á–∏–π —É–∑–µ–ª |
| k3s-worker-2 | 4 | 10GB | 80GB (SSD) | vmbr1 | 192.168.100.12 | K3s —Ä–∞–±–æ—á–∏–π —É–∑–µ–ª |
| jenkins | 2 | 4GB | 40GB | vmbr1 | 192.168.100.101 | CI —Å–µ—Ä–≤–µ—Ä |
| minio | 2 | 4GB | 20GB+100GB (HDD) | vmbr1 | 192.168.100.20 | –û–±—ä–µ–∫—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ |
| jumphost | 1 | 2GB | 20GB | vmbr0+vmbr1 | 10.0.10.102<br>192.168.100.5 | –•–æ—Å—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è |

**–í—Å–µ–≥–æ —Ä–µ—Å—É—Ä—Å–æ–≤**: 19 vCPU, 40GB RAM, 420GB –¥–∏—Å–∫

### üÜï –ö–∞—Ä—Ç–∞ —Å–µ—Ä–≤–∏—Å–æ–≤ v2.0

| –°–µ—Ä–≤–∏—Å | –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –¥–æ–º–µ–Ω | –í–Ω–µ—à–Ω–∏–π –¥–æ–º–µ–Ω | –ü–æ—Ä—Ç | –ù–æ–≤–æ–µ |
|---------|----------------|-----------------|------|-------|
| EzyShop | ezyshop.local.lab | ezyshop.yourdomain.com | 80/443 | üÜï Canary |
| ArgoCD | argocd.local.lab | argocd.yourdomain.com | 80/443 | - |
| Grafana | grafana.local.lab | grafana.yourdomain.com | 80/443 | - |
| Prometheus | prometheus.local.lab | prometheus.yourdomain.com | 80/443 | - |
| AlertManager | alertmanager.local.lab | alertmanager.yourdomain.com | 80/443 | - |
| Kibana | kibana.local.lab | kibana.yourdomain.com | 80/443 | - |
| Jenkins | jenkins.local.lab | jenkins.yourdomain.com | 8080 | üÜï Trivy |
| MinIO –∫–æ–Ω—Å–æ–ª—å | minio.local.lab | - | 9001 | üÜï Backups |
| Longhorn UI | longhorn.local.lab | - | 80 | - |
| üÜï Vault UI | vault.local.lab | - | 8200 | üÜï NEW |
| üÜï Argo Rollouts | rollouts.local.lab | - | 3100 | üÜï NEW |

---

## ‚úÖ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ
- –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π Proxmox VE 8.x
- –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π ISO Ubuntu 22.04 –≤ Proxmox
- –ê–∫–∫–∞—É–Ω—Ç Cloudflare (–¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞)
- –ê–∫–∫–∞—É–Ω—Ç GitHub/GitLab
- –ë–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è Linux, Kubernetes –∏ CI/CD

### üÜï –ù–æ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è v2.0
- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ 20GB –¥–∏—Å–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –¥–ª—è backup
- MinIO credentials –¥–ª—è Velero (—Å–æ–∑–¥–∞–¥–∏–º –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ)
- Slack Webhook URL –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –∞–ª–µ—Ä—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

---

## üìñ –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ

### –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞

**–®–ê–ì 1-9: –°–ª–µ–¥—É–π—Ç–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏**

> üí° **–í–∞–∂–Ω–æ**: –°–Ω–∞—á–∞–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤—Å—é –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (—à–∞–≥–∏ 1-9):
> - –°–µ—Ç–µ–≤–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞
> - DNS —Å–µ—Ä–≤–µ—Ä (BIND9)
> - NAT —à–ª—é–∑
> - MinIO
> - K3s –∫–ª–∞—Å—Ç–µ—Ä
> - Longhorn
> - MetalLB
> - Traefik
> - Cloudflare Tunnel

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –±–∞–∑–æ–≤–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏, –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ –Ω–æ–≤—ã–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º:

---

### 10. CI/CD (Jenkins)

> –°–ª–µ–¥—É–π—Ç–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∑–∞—Ç–µ–º –¥–æ–±–∞–≤—å—Ç–µ Trivy:

#### üÜï –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Trivy Scanner

SSH –∫ jenkins:

```bash
ssh admin@jenkins.local.lab

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Trivy
sudo apt-get install wget apt-transport-https gnupg lsb-release -y
wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | gpg --dearmor | sudo tee /usr/share/keyrings/trivy.gpg > /dev/null
echo "deb [signed-by=/usr/share/keyrings/trivy.gpg] https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
sudo apt-get update
sudo apt-get install trivy -y

# –ü—Ä–æ–≤–µ—Ä–∫–∞
trivy --version

# –¢–µ—Å—Ç–æ–≤–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
trivy image nginx:latest
```

#### üÜï –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Jenkins –¥–ª—è Trivy

–í Jenkins UI (`http://jenkins.local.lab:8080`):

1. **Manage Jenkins** ‚Üí **Manage Plugins**
2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–ª–∞–≥–∏–Ω—ã:
   - Pipeline
   - Docker Pipeline
   - Git

3. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π Pipeline job: **ezyshop-ci-cd-v2**

4. Pipeline Script (–ø—Ä–∏–º–µ—Ä —Å Trivy):

```groovy
pipeline {
    agent any
    
    environment {
        DOCKER_IMAGE = "ezyshop/frontend"
        DOCKER_TAG = "${BUILD_NUMBER}"
        K8S_NAMESPACE = "ezyshop"
        TRIVY_SEVERITY = "HIGH,CRITICAL"
    }
    
    stages {
        stage('Checkout') {
            steps {
                git branch: 'main', 
                    url: 'https://github.com/yourusername/ezyshop.git'
            }
        }
        
        stage('Build') {
            steps {
                script {
                    sh """
                        docker build -t ${DOCKER_IMAGE}:${DOCKER_TAG} .
                        docker tag ${DOCKER_IMAGE}:${DOCKER_TAG} ${DOCKER_IMAGE}:latest
                    """
                }
            }
        }
        
        stage('üÜï Security Scan - Trivy') {
            steps {
                script {
                    sh """
                        echo "Scanning image for vulnerabilities..."
                        trivy image \
                            --severity ${TRIVY_SEVERITY} \
                            --exit-code 0 \
                            --no-progress \
                            ${DOCKER_IMAGE}:${DOCKER_TAG}
                    """
                    
                    // –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç
                    sh """
                        trivy image \
                            --severity ${TRIVY_SEVERITY} \
                            --format json \
                            --output trivy-report.json \
                            ${DOCKER_IMAGE}:${DOCKER_TAG}
                    """
                    
                    // –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: Fail pipeline –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã CRITICAL —É—è–∑–≤–∏–º–æ—Å—Ç–∏
                    sh """
                        CRITICAL_COUNT=\$(trivy image \
                            --severity CRITICAL \
                            --format json \
                            ${DOCKER_IMAGE}:${DOCKER_TAG} | \
                            jq '[.Results[].Vulnerabilities[]? | select(.Severity=="CRITICAL")] | length')
                        
                        if [ "\$CRITICAL_COUNT" -gt 0 ]; then
                            echo "‚ùå Found \$CRITICAL_COUNT CRITICAL vulnerabilities!"
                            echo "‚ö†Ô∏è  Building anyway, but please review!"
                        fi
                    """
                }
            }
        }
        
        stage('Push to Registry') {
            steps {
                script {
                    sh """
                        docker push ${DOCKER_IMAGE}:${DOCKER_TAG}
                        docker push ${DOCKER_IMAGE}:latest
                    """
                }
            }
        }
        
        stage('üÜï Deploy with Argo Rollouts') {
            steps {
                script {
                    sh """
                        # –û–±–Ω–æ–≤–∏—Ç—å image –≤ Rollout
                        kubectl argo rollouts set image ezyshop-frontend \
                            frontend=${DOCKER_IMAGE}:${DOCKER_TAG} \
                            -n ${K8S_NAMESPACE}
                        
                        # –°–ª–µ–¥–∏—Ç—å –∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º (timeout 10 –º–∏–Ω—É—Ç)
                        kubectl argo rollouts status ezyshop-frontend \
                            -n ${K8S_NAMESPACE} \
                            --watch \
                            --timeout 10m
                    """
                }
            }
        }
    }
    
    post {
        always {
            archiveArtifacts artifacts: 'trivy-report.json', allowEmptyArchive: true
        }
        success {
            echo '‚úÖ Pipeline completed successfully!'
        }
        failure {
            echo '‚ùå Pipeline failed!'
        }
    }
}
```

---

### 11. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (Prometheus Stack)

> –°–ª–µ–¥—É–π—Ç–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π

---

### 12. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (ELK Stack)

> –°–ª–µ–¥—É–π—Ç–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π

---

### 13. GitOps (ArgoCD)

> –°–ª–µ–¥—É–π—Ç–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∑–∞—Ç–µ–º –¥–æ–±–∞–≤—å—Ç–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å Argo Rollouts (—Å–º. —à–∞–≥ 16)

---

### 14. üÜï –ù–û–í–û–ï: Security Layer (Vault + Trivy)

#### A. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ HashiCorp Vault

–° jumphost:

```bash
# –î–æ–±–∞–≤–∏—Ç—å Helm —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
helm repo add hashicorp https://helm.releases.hashicorp.com
helm repo update

# –°–æ–∑–¥–∞—Ç—å namespace
kubectl create namespace vault-system

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Vault –≤ dev —Ä–µ–∂–∏–º–µ (–¥–ª—è testing)
# ‚ö†Ô∏è –í production –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ HA —Ä–µ–∂–∏–º —Å Raft –∏–ª–∏ Consul!
helm install vault hashicorp/vault \
    --namespace vault-system \
    --set "server.dev.enabled=true" \
    --set "server.dev.devRootToken=root" \
    --set "injector.enabled=true" \
    --set "ui.enabled=true" \
    --set "ui.serviceType=ClusterIP"

# –ü–æ–¥–æ–∂–¥–∞—Ç—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
kubectl -n vault-system get pods -w
```

#### B. –°–æ–∑–¥–∞–Ω–∏–µ Ingress –¥–ª—è Vault UI

```bash
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: vault-ingress
  namespace: vault-system
spec:
  rules:
  - host: vault.local.lab
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: vault-ui
            port:
              number: 8200
EOF
```

**–î–æ—Å—Ç—É–ø**: `http://vault.local.lab` (token: `root`)

#### C. –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–æ–≤ –≤ Vault

```bash
# –í–æ–π—Ç–∏ –≤ –ø–æ–¥ Vault
kubectl -n vault-system exec -it vault-0 -- /bin/sh

# –í–∫–ª—é—á–∏—Ç—å KV secrets engine
vault secrets enable -path=secret kv-v2

# –°–æ–∑–¥–∞—Ç—å —Å–µ–∫—Ä–µ—Ç—ã –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
vault kv put secret/ezyshop/database \
    username=ezyshop \
    password=SuperSecretPassword123

vault kv put secret/ezyshop/api \
    api_key=your-api-key-here \
    jwt_secret=your-jwt-secret-here

# –°–æ–∑–¥–∞—Ç—å —Å–µ–∫—Ä–µ—Ç—ã –¥–ª—è MinIO (–¥–ª—è Velero)
vault kv put secret/minio \
    access_key=minioadmin \
    secret_key=minioadmin123

# –ü—Ä–æ–≤–µ—Ä–∫–∞
vault kv get secret/ezyshop/database

exit
```

#### D. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Kubernetes Auth

```bash
kubectl -n vault-system exec -it vault-0 -- /bin/sh

# –í–∫–ª—é—á–∏—Ç—å Kubernetes auth
vault auth enable kubernetes

# –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Kubernetes auth
vault write auth/kubernetes/config \
    kubernetes_host="https://kubernetes.default.svc:443"

# –°–æ–∑–¥–∞—Ç—å policy –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
vault policy write ezyshop - <<EOF
path "secret/data/ezyshop/*" {
  capabilities = ["read"]
}
EOF

# –°–æ–∑–¥–∞—Ç—å —Ä–æ–ª—å –¥–ª—è namespace ezyshop
vault write auth/kubernetes/role/ezyshop \
    bound_service_account_names=ezyshop-sa \
    bound_service_account_namespaces=ezyshop \
    policies=ezyshop \
    ttl=24h

exit
```

#### E. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–æ–≤ –≤ –ø–æ–¥–∞—Ö

```bash
# –°–æ–∑–¥–∞—Ç—å ServiceAccount
kubectl create namespace ezyshop
kubectl create serviceaccount ezyshop-sa -n ezyshop

# Deployment —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–µ–π –¥–ª—è Vault injection
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ezyshop-backend
  namespace: ezyshop
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ezyshop-backend
  template:
    metadata:
      labels:
        app: ezyshop-backend
      annotations:
        vault.hashicorp.com/agent-inject: "true"
        vault.hashicorp.com/role: "ezyshop"
        vault.hashicorp.com/agent-inject-secret-database: "secret/data/ezyshop/database"
        vault.hashicorp.com/agent-inject-template-database: |
          {{- with secret "secret/data/ezyshop/database" -}}
          export DB_USERNAME="{{ .Data.data.username }}"
          export DB_PASSWORD="{{ .Data.data.password }}"
          {{- end }}
    spec:
      serviceAccountName: ezyshop-sa
      containers:
      - name: backend
        image: ezyshop/backend:latest
        command: ["/bin/sh", "-c"]
        args:
          - source /vault/secrets/database && ./start-app.sh
        ports:
        - containerPort: 8080
EOF
```

#### F. üÜï Network Policies

```bash
# 1. Deny all ingress traffic –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-ingress
  namespace: ezyshop
spec:
  podSelector: {}
  policyTypes:
  - Ingress
EOF

# 2. –†–∞–∑—Ä–µ—à–∏—Ç—å —Ç—Ä–∞—Ñ–∏–∫ –æ—Ç Ingress –∫ Frontend
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-ingress-to-frontend
  namespace: ezyshop
spec:
  podSelector:
    matchLabels:
      app: ezyshop-frontend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: traefik
    ports:
    - protocol: TCP
      port: 80
EOF

# 3. –†–∞–∑—Ä–µ—à–∏—Ç—å Frontend ‚Üí Backend
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-to-backend
  namespace: ezyshop
spec:
  podSelector:
    matchLabels:
      app: ezyshop-backend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: ezyshop-frontend
    ports:
    - protocol: TCP
      port: 8080
EOF

# 4. –†–∞–∑—Ä–µ—à–∏—Ç—å Backend ‚Üí PostgreSQL
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-backend-to-postgres
  namespace: ezyshop
spec:
  podSelector:
    matchLabels:
      app: postgres
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: ezyshop-backend
    ports:
    - protocol: TCP
      port: 5432
EOF

# 5. –†–∞–∑—Ä–µ—à–∏—Ç—å Prometheus scraping
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-prometheus-scraping
  namespace: ezyshop
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 9090
EOF

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Network Policies
kubectl get networkpolicies -n ezyshop
```

---

### 15. üÜï –ù–û–í–û–ï: Backup & DR (Velero)

#### A. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ MinIO –¥–ª—è Velero

SSH –∫ minio:

```bash
ssh admin@minio.local.lab

# –í–æ–π—Ç–∏ –≤ MinIO Console: http://minio.local.lab:9001
# User: minioadmin, Password: minioadmin123
```

–í MinIO Console:
1. –°–æ–∑–¥–∞–π—Ç–µ bucket: **velero-backups**
2. –°–æ–∑–¥–∞–π—Ç–µ Access Key –¥–ª—è Velero:
   - Access Key: `velero`
   - Secret Key: `velero-secret-key-123`

#### B. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Velero CLI

–° jumphost:

```bash
# –°–∫–∞—á–∞—Ç—å Velero CLI
wget https://github.com/vmware-tanzu/velero/releases/download/v1.12.1/velero-v1.12.1-linux-amd64.tar.gz
tar -xvf velero-v1.12.1-linux-amd64.tar.gz
sudo mv velero-v1.12.1-linux-amd64/velero /usr/local/bin/
velero version --client-only
```

#### C. –°–æ–∑–¥–∞–Ω–∏–µ credentials —Ñ–∞–π–ª–∞

```bash
cat > /tmp/credentials-velero <<EOF
[default]
aws_access_key_id=velero
aws_secret_access_key=velero-secret-key-123
EOF
```

#### D. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Velero –≤ –∫–ª–∞—Å—Ç–µ—Ä

```bash
velero install \
    --provider aws \
    --plugins velero/velero-plugin-for-aws:v1.8.0 \
    --bucket velero-backups \
    --secret-file /tmp/credentials-velero \
    --use-volume-snapshots=false \
    --backup-location-config \
region=minio,s3ForcePathStyle="true",s3Url=http://minio.local.lab:9000 \
    --namespace velero

# –ü—Ä–æ–≤–µ—Ä–∫–∞
kubectl -n velero get pods
velero version
```

#### E. –°–æ–∑–¥–∞–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö backup schedules

```bash
# 1. –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø–æ–ª–Ω—ã–π backup –∫–ª–∞—Å—Ç–µ—Ä–∞ (02:00 UTC)
velero schedule create daily-full-backup \
    --schedule="0 2 * * *" \
    --ttl 720h0m0s

# 2. –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π backup –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (03:00 UTC)
velero schedule create daily-ezyshop-backup \
    --schedule="0 3 * * *" \
    --include-namespaces ezyshop \
    --ttl 720h0m0s

# 3. –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–π backup –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö namespace (–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ 04:00 UTC)
velero schedule create weekly-critical-backup \
    --schedule="0 4 * * 0" \
    --include-namespaces ezyshop,monitoring,logging,argocd,vault-system \
    --ttl 2160h0m0s

# –ü—Ä–æ–≤–µ—Ä–∫–∞ schedules
velero schedule get

# –†—É—á–Ω–æ–π backup –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
velero backup create test-backup --wait
velero backup describe test-backup
velero backup logs test-backup
```

#### F. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ PostgreSQL Snapshots

```bash
# –°–æ–∑–¥–∞—Ç—å PVC –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è backup
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-backups
  namespace: ezyshop
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: longhorn
  resources:
    requests:
      storage: 50Gi
EOF

# –°–æ–∑–¥–∞—Ç—å Secret —Å –ø–∞—Ä–æ–ª–µ–º PostgreSQL
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
  namespace: ezyshop
type: Opaque
stringData:
  password: "SuperSecretPassword123"
EOF

# CronJob –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö backup –∫–∞–∂–¥—ã–µ 3 —á–∞—Å–∞
cat <<EOF | kubectl apply -f -
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
  namespace: ezyshop
spec:
  schedule: "0 */3 * * *"  # –ö–∞–∂–¥—ã–µ 3 —á–∞—Å–∞
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: postgres:15-alpine
            command:
            - /bin/sh
            - -c
            - |
              set -e
              TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
              BACKUP_FILE="/backups/ezyshop_\${TIMESTAMP}.sql.gz"
              
              echo "Starting backup at \$(date)"
              echo "Target: \${BACKUP_FILE}"
              
              # –í—ã–ø–æ–ª–Ω–∏—Ç—å backup
              pg_dump -h postgres -U ezyshop -d ezyshop | gzip > "\${BACKUP_FILE}"
              
              if [ -f "\${BACKUP_FILE}" ]; then
                SIZE=\$(du -h "\${BACKUP_FILE}" | cut -f1)
                echo "‚úÖ Backup completed: \${BACKUP_FILE} (Size: \${SIZE})"
              else
                echo "‚ùå Backup failed!"
                exit 1
              fi
              
              # –£–¥–∞–ª–∏—Ç—å backup —Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π
              echo "Cleaning old backups..."
              find /backups -name "*.sql.gz" -mtime +7 -delete
              
              # –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ backup
              echo "Available backups:"
              ls -lh /backups/*.sql.gz | tail -10
            env:
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: password
            volumeMounts:
            - name: backups
              mountPath: /backups
          volumes:
          - name: backups
            persistentVolumeClaim:
              claimName: postgres-backups
          restartPolicy: OnFailure
EOF

# –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
kubectl create job -n ezyshop postgres-backup-manual \
    --from=cronjob/postgres-backup

# –°–ª–µ–¥–∏—Ç—å –∑–∞ –ª–æ–≥–∞–º–∏
kubectl -n ezyshop logs -f job/postgres-backup-manual

# –ü—Ä–æ–≤–µ—Ä–∫–∞ backup —Ñ–∞–π–ª–æ–≤
kubectl -n ezyshop exec -it deployment/postgres -- ls -lh /backups/
```

#### G. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Disaster Recovery

```bash
# === –¢–ï–°–¢ 1: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ namespace ===

# 1. –£–¥–∞–ª–∏—Ç—å namespace (—Å–∏–º—É–ª—è—Ü–∏—è –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ—ã)
kubectl delete namespace ezyshop --wait=false

# 2. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ backup
LATEST_BACKUP=$(velero backup get | grep ezyshop | head -1 | awk '{print $1}')
velero restore create --from-backup $LATEST_BACKUP --wait

# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞
kubectl -n ezyshop get pods

# === –¢–ï–°–¢ 2: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ë–î ===

# 1. –í—ã–±—Ä–∞—Ç—å backup —Ñ–∞–π–ª
kubectl -n ezyshop exec -it deployment/postgres -- ls -lh /backups/

# 2. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ë–î (–∑–∞–º–µ–Ω–∏—Ç–µ TIMESTAMP)
kubectl -n ezyshop exec -it deployment/postgres -- bash -c \
  "gunzip -c /backups/ezyshop_TIMESTAMP.sql.gz | psql -U ezyshop -d ezyshop"

# === –¢–ï–°–¢ 3: –ü–æ–ª–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∞ ===

# 1. –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö backup
velero backup get

# 2. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–µ—Å—å –∫–ª–∞—Å—Ç–µ—Ä
velero restore create full-restore \
    --from-backup daily-full-backup-TIMESTAMP \
    --wait

# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
velero restore describe full-restore
kubectl get pods -A
```

---

### 16. üÜï –ù–û–í–û–ï: Canary Deployments (Argo Rollouts)

#### A. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Argo Rollouts

```bash
# –°–æ–∑–¥–∞—Ç—å namespace
kubectl create namespace argo-rollouts

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ controller
kubectl apply -n argo-rollouts -f \
  https://github.com/argoproj/argo-rollouts/releases/latest/download/install.yaml

# –ü–æ–¥–æ–∂–¥–∞—Ç—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
kubectl -n argo-rollouts get pods -w

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ kubectl plugin
curl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-linux-amd64
chmod +x kubectl-argo-rollouts-linux-amd64
sudo mv kubectl-argo-rollouts-linux-amd64 /usr/local/bin/kubectl-argo-rollouts

# –ü—Ä–æ–≤–µ—Ä–∫–∞
kubectl argo rollouts version
```

#### B. –°–æ–∑–¥–∞–Ω–∏–µ Rollout Dashboard

```bash
# –°–æ–∑–¥–∞—Ç—å Ingress –¥–ª—è Dashboard
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: argo-rollouts-dashboard
  namespace: argo-rollouts
spec:
  type: ClusterIP
  ports:
  - port: 3100
    targetPort: 3100
    name: dashboard
  selector:
    app.kubernetes.io/name: argo-rollouts
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: argo-rollouts-ingress
  namespace: argo-rollouts
spec:
  rules:
  - host: rollouts.local.lab
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: argo-rollouts-dashboard
            port:
              number: 3100
EOF

# –ó–∞–ø—É—Å—Ç–∏—Ç—å Dashboard
kubectl argo rollouts dashboard -n argo-rollouts &

# –î–æ—Å—Ç—É–ø: http://rollouts.local.lab
```

#### C. Analysis Template (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç—Ä–∏–∫)

```bash
cat <<EOF | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: success-rate
  namespace: ezyshop
spec:
  metrics:
  - name: success-rate
    interval: 1m
    successCondition: result[0] >= 0.95
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus-kube-prometheus-prometheus.monitoring:9090
        query: |
          sum(rate(
            http_requests_total{
              namespace="ezyshop",
              status=~"2.."
            }[5m]
          )) 
          /
          sum(rate(
            http_requests_total{
              namespace="ezyshop"
            }[5m]
          ))
  - name: latency
    interval: 1m
    successCondition: result[0] <= 0.5
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus-kube-prometheus-prometheus.monitoring:9090
        query: |
          histogram_quantile(0.95,
            sum(rate(
              http_request_duration_seconds_bucket{
                namespace="ezyshop"
              }[5m]
            )) by (le)
          )
---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: error-rate
  namespace: ezyshop
spec:
  metrics:
  - name: error-rate
    interval: 1m
    successCondition: result[0] <= 0.05
    failureLimit: 2
    provider:
      prometheus:
        address: http://prometheus-kube-prometheus-prometheus.monitoring:9090
        query: |
          sum(rate(
            http_requests_total{
              namespace="ezyshop",
              status=~"5.."
            }[5m]
          ))
          /
          sum(rate(
            http_requests_total{
              namespace="ezyshop"
            }[5m]
          ))
EOF
```

#### D. –°–æ–∑–¥–∞–Ω–∏–µ Rollout –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

```bash
cat <<EOF | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: ezyshop-frontend
  namespace: ezyshop
spec:
  replicas: 5
  revisionHistoryLimit: 3
  selector:
    matchLabels:
      app: ezyshop-frontend
  template:
    metadata:
      labels:
        app: ezyshop-frontend
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
    spec:
      containers:
      - name: frontend
        image: ezyshop/frontend:v1.0.0
        ports:
        - containerPort: 80
          name: http
        - containerPort: 9090
          name: metrics
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        livenessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
  strategy:
    canary:
      # Canary Service (–¥–ª—è –Ω–æ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞)
      canaryService: ezyshop-frontend-canary
      # Stable Service (–¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞)
      stableService: ezyshop-frontend-stable
      
      # –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ —Ä–∞—Å–∫–∞—Ç—ã–≤–∞–Ω–∏–µ
      steps:
      - setWeight: 20
      - pause: {duration: 5m}
      - analysis:
          templates:
          - templateName: success-rate
          - templateName: error-rate
      
      - setWeight: 40
      - pause: {duration: 5m}
      - analysis:
          templates:
          - templateName: success-rate
      
      - setWeight: 60
      - pause: {duration: 5m}
      - analysis:
          templates:
          - templateName: success-rate
      
      - setWeight: 80
      - pause: {duration: 5m}
      - analysis:
          templates:
          - templateName: success-rate
      
      # –ü–æ–ª–Ω—ã–π rollout
      - setWeight: 100
      
      # Traffic routing —á–µ—Ä–µ–∑ Traefik
      trafficRouting:
        traefik:
          weightedTraefikServiceName: ezyshop-frontend-weighted
---
apiVersion: v1
kind: Service
metadata:
  name: ezyshop-frontend-stable
  namespace: ezyshop
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 80
    name: http
  selector:
    app: ezyshop-frontend
---
apiVersion: v1
kind: Service
metadata:
  name: ezyshop-frontend-canary
  namespace: ezyshop
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 80
    name: http
  selector:
    app: ezyshop-frontend
---
apiVersion: v1
kind: Service
metadata:
  name: ezyshop-frontend
  namespace: ezyshop
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 80
    name: http
  selector:
    app: ezyshop-frontend
EOF
```

#### E. HPA + PDB –¥–ª—è –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è

```bash
# Horizontal Pod Autoscaler
cat <<EOF | kubectl apply -f -
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ezyshop-frontend-hpa
  namespace: ezyshop
spec:
  scaleTargetRef:
    apiVersion: argoproj.io/v1alpha1
    kind: Rollout
    name: ezyshop-frontend
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
      - type: Pods
        value: 2
        periodSeconds: 30
      selectPolicy: Max
EOF

# Pod Disruption Budget (–∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ª—É—á–∞–π–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è)
cat <<EOF | kubectl apply -f -
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: ezyshop-frontend-pdb
  namespace: ezyshop
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: ezyshop-frontend
EOF

# –ü—Ä–æ–≤–µ—Ä–∫–∞
kubectl -n ezyshop get hpa
kubectl -n ezyshop get pdb
```

#### F. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Canary Deployment

```bash
# === –ú–ï–¢–û–î 1: –ß–µ—Ä–µ–∑ kubectl plugin ===

# 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏
kubectl argo rollouts get rollout ezyshop-frontend -n ezyshop

# 2. –û–±–Ω–æ–≤–∏—Ç—å image (—Ç—Ä–∏–≥–≥–µ—Ä canary)
kubectl argo rollouts set image ezyshop-frontend \
  frontend=ezyshop/frontend:v2.0.0 \
  -n ezyshop

# 3. –°–ª–µ–¥–∏—Ç—å –∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
kubectl argo rollouts get rollout ezyshop-frontend -n ezyshop --watch

# 4. –†—É—á–Ω–æ–µ –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ manual pause)
kubectl argo rollouts promote ezyshop-frontend -n ezyshop

# 5. –†—É—á–Ω–æ–π rollback (–µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫)
kubectl argo rollouts abort ezyshop-frontend -n ezyshop
kubectl argo rollouts undo ezyshop-frontend -n ezyshop

# === –ú–ï–¢–û–î 2: –ß–µ—Ä–µ–∑ Dashboard ===
# –û—Ç–∫—Ä–æ–π—Ç–µ: http://rollouts.local.lab
# –í–∏–∑—É–∞–ª—å–Ω–æ —Å–ª–µ–¥–∏—Ç–µ –∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º, –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π—Ç–µ rollout

# === –ú–ï–¢–û–î 3: Stress test –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ HPA ===

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Apache Bench
sudo apt install apache2-utils -y

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏
ab -n 10000 -c 100 http://ezyshop.local.lab/

# –°–ª–µ–¥–∏—Ç—å –∑–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º
watch kubectl -n ezyshop get hpa
watch kubectl -n ezyshop get pods
```

---

### 17. –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

#### –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å Rollout

```bash
# –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –º–∞–Ω–∏—Ñ–µ—Å—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Namespace
metadata:
  name: ezyshop
  labels:
    name: ezyshop
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ezyshop-sa
  namespace: ezyshop
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ezyshop-config
  namespace: ezyshop
data:
  APP_ENV: "production"
  LOG_LEVEL: "info"
  DB_HOST: "postgres"
  DB_PORT: "5432"
  DB_NAME: "ezyshop"
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: ezyshop
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15-alpine
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_DB
          value: ezyshop
        - name: POSTGRES_USER
          value: ezyshop
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
        - name: postgres-backups
          mountPath: /backups
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 2000m
            memory: 2Gi
  volumeClaimTemplates:
  - metadata:
      name: postgres-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: longhorn
      resources:
        requests:
          storage: 20Gi
---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: ezyshop
spec:
  type: ClusterIP
  ports:
  - port: 5432
    targetPort: 5432
  selector:
    app: postgres
---
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: ezyshop-backend
  namespace: ezyshop
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ezyshop-backend
  template:
    metadata:
      labels:
        app: ezyshop-backend
      annotations:
        vault.hashicorp.com/agent-inject: "true"
        vault.hashicorp.com/role: "ezyshop"
        vault.hashicorp.com/agent-inject-secret-database: "secret/data/ezyshop/database"
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
    spec:
      serviceAccountName: ezyshop-sa
      containers:
      - name: backend
        image: ezyshop/backend:v1.0.0
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 9090
          name: metrics
        envFrom:
        - configMapRef:
            name: ezyshop-config
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
  strategy:
    canary:
      canaryService: ezyshop-backend-canary
      stableService: ezyshop-backend-stable
      steps:
      - setWeight: 25
      - pause: {duration: 3m}
      - setWeight: 50
      - pause: {duration: 3m}
      - setWeight: 75
      - pause: {duration: 3m}
      analysis:
        templates:
        - templateName: success-rate
        startingStep: 1
---
apiVersion: v1
kind: Service
metadata:
  name: ezyshop-backend-stable
  namespace: ezyshop
spec:
  ports:
  - port: 8080
    targetPort: 8080
  selector:
    app: ezyshop-backend
---
apiVersion: v1
kind: Service
metadata:
  name: ezyshop-backend-canary
  namespace: ezyshop
spec:
  ports:
  - port: 8080
    targetPort: 8080
  selector:
    app: ezyshop-backend
---
apiVersion: v1
kind: Service
metadata:
  name: ezyshop-backend
  namespace: ezyshop
spec:
  ports:
  - port: 8080
    targetPort: 8080
  selector:
    app: ezyshop-backend
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ezyshop-ingress
  namespace: ezyshop
  annotations:
    traefik.ingress.kubernetes.io/router.entrypoints: web,websecure
spec:
  rules:
  - host: ezyshop.local.lab
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: ezyshop-backend
            port:
              number: 8080
      - path: /
        pathType: Prefix
        backend:
          service:
            name: ezyshop-frontend
            port:
              number: 80
EOF

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
kubectl -n ezyshop get all
kubectl argo rollouts get rollout ezyshop-frontend -n ezyshop
kubectl argo rollouts get rollout ezyshop-backend -n ezyshop
```

---

## üîÑ CI/CD –ø–∞–π–ø–ª–∞–π–Ω v2.0

### –ü–æ–ª–Ω—ã–π GitOps workflow —Å Security + Canary

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Developer Push                                       ‚îÇ
‚îÇ     git push origin main                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. Jenkins CI (Webhook)                                 ‚îÇ
‚îÇ     - Checkout code                                      ‚îÇ
‚îÇ     - Build application                                  ‚îÇ
‚îÇ     - Run unit tests                                     ‚îÇ
‚îÇ     - Build Docker image                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. üÜï Security Scan (Trivy)                            ‚îÇ
‚îÇ     - Scan image for vulnerabilities                     ‚îÇ
‚îÇ     - Check for HIGH/CRITICAL CVEs                       ‚îÇ
‚îÇ     - Generate security report                           ‚îÇ
‚îÇ     - ‚ö†Ô∏è  Fail if CRITICAL found (optional)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. Push to Registry                                     ‚îÇ
‚îÇ     - docker push ezyshop/app:v2.0.0                    ‚îÇ
‚îÇ     - docker push ezyshop/app:latest                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. Update Manifest                                      ‚îÇ
‚îÇ     - Update image tag in k8s manifests                  ‚îÇ
‚îÇ     - git push to manifest repo                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  6. ArgoCD GitOps                                        ‚îÇ
‚îÇ     - Detect manifest changes                            ‚îÇ
‚îÇ     - Sync with cluster                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  7. üÜï Argo Rollouts (Canary)                           ‚îÇ
‚îÇ     Step 1: 20% traffic ‚Üí new version (5min)            ‚îÇ
‚îÇ     ‚îú‚îÄ Analysis: Check success rate > 95%               ‚îÇ
‚îÇ     ‚îú‚îÄ Analysis: Check latency < 500ms                  ‚îÇ
‚îÇ     ‚îî‚îÄ ‚úÖ Pass ‚Üí Continue | ‚ùå Fail ‚Üí Auto Rollback     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ     Step 2: 40% traffic ‚Üí new version (5min)            ‚îÇ
‚îÇ     ‚îî‚îÄ Analysis: Check metrics                          ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ     Step 3: 60% traffic ‚Üí new version (5min)            ‚îÇ
‚îÇ     ‚îî‚îÄ Analysis: Check metrics                          ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ     Step 4: 80% traffic ‚Üí new version (5min)            ‚îÇ
‚îÇ     ‚îî‚îÄ Analysis: Check metrics                          ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ     Step 5: 100% traffic ‚Üí new version                  ‚îÇ
‚îÇ     ‚îî‚îÄ ‚úÖ Deployment Complete!                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  8. Monitoring & Alerting                                ‚îÇ
‚îÇ     - Prometheus scrapes metrics                         ‚îÇ
‚îÇ     - Grafana visualizes                                 ‚îÇ
‚îÇ     - AlertManager ‚Üí Slack (if issues)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üìä Total Deployment Time: ~25-30 minutes (with canary)
üéØ Zero Downtime: ‚úÖ Yes
üîÑ Auto Rollback: ‚úÖ Yes (if metrics fail)
```

---

## üíæ Disaster Recovery –ø—Ä–æ—Ü–µ–¥—É—Ä—ã

### –°—Ü–µ–Ω–∞—Ä–∏–π 1: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (RPO: 3 —á–∞—Å–∞)

```bash
# –®–∞–≥ 1: –ù–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π backup
velero backup get | grep ezyshop

# –®–∞–≥ 2: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å namespace
velero restore create ezyshop-restore \
    --from-backup daily-ezyshop-backup-20241002030000 \
    --wait

# –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä–∫–∞
kubectl -n ezyshop get pods
kubectl -n ezyshop get pvc

# –®–∞–≥ 4: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ë–î –∏–∑ snapshot
LATEST_DB=$(kubectl -n ezyshop exec deployment/postgres -- \
    ls -t /backups/*.sql.gz | head -1)

kubectl -n ezyshop exec -it deployment/postgres -- bash -c \
    "gunzip -c $LATEST_DB | psql -U ezyshop -d ezyshop"

# –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
curl http://ezyshop.local.lab/health

# ‚è±Ô∏è –í—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: ~15-20 –º–∏–Ω—É—Ç
```

### –°—Ü–µ–Ω–∞—Ä–∏–π 2: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Å–µ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞ (RPO: 24 —á–∞—Å–∞)

```bash
# –®–∞–≥ 1: –ù–æ–≤—ã–π K3s –∫–ª–∞—Å—Ç–µ—Ä —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –≥–æ—Ç–æ–≤

# –®–∞–≥ 2: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Velero –Ω–∞ –Ω–æ–≤—ã–π –∫–ª–∞—Å—Ç–µ—Ä
velero install \
    --provider aws \
    --plugins velero/velero-plugin-for-aws:v1.8.0 \
    --bucket velero-backups \
    --secret-file /tmp/credentials-velero \
    --use-volume-snapshots=false \
    --backup-location-config \
region=minio,s3ForcePathStyle="true",s3Url=http://minio.local.lab:9000

# –®–∞–≥ 3: –ù–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ–ª–Ω—ã–π backup
velero backup get

# –®–∞–≥ 4: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ
velero restore create full-cluster-restore \
    --from-backup daily-full-backup-20241002020000 \
    --wait

# –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö namespace
kubectl get namespaces
kubectl get pods -A

# –®–∞–≥ 6: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ë–î
# (—Å–º. –°—Ü–µ–Ω–∞—Ä–∏–π 1, –®–∞–≥ 4)

# ‚è±Ô∏è –í—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: ~30-45 –º–∏–Ω—É—Ç
```

### –°—Ü–µ–Ω–∞—Ä–∏–π 3: Rollback –ø–æ—Å–ª–µ –Ω–µ—É–¥–∞—á–Ω–æ–≥–æ deployment

```bash
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π rollback (—á–µ—Ä–µ–∑ Argo Rollouts Analysis)
# –ü—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –µ—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∏ –ø–∞–¥–∞—é—Ç –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞

# –†—É—á–Ω–æ–π rollback
kubectl argo rollouts abort ezyshop-frontend -n ezyshop
kubectl argo rollouts undo ezyshop-frontend -n ezyshop

# –ü—Ä–æ–≤–µ—Ä–∫–∞
kubectl argo rollouts get rollout ezyshop-frontend -n ezyshop

# ‚è±Ô∏è –í—Ä–µ–º—è rollback: ~2-3 –º–∏–Ω—É—Ç—ã
```

### RTO/RPO –ú–∞—Ç—Ä–∏—Ü–∞

| –°—Ü–µ–Ω–∞—Ä–∏–π | RTO | RPO | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π |
|----------|-----|-----|----------------|
| Pod crash | < 1 –º–∏–Ω | 0 | ‚úÖ Kubernetes |
| Node failure | < 5 –º–∏–Ω | 0 | ‚úÖ K3s HA |
| Deployment issue | < 3 –º–∏–Ω | 0 | ‚úÖ Argo Rollouts |
| Namespace deletion | < 15 –º–∏–Ω | 3 —á–∞—Å–∞ | ‚ùå Manual Velero |
| Database corruption | < 20 –º–∏–Ω | 3 —á–∞—Å–∞ | ‚ùå Manual restore |
| Full cluster loss | < 45 –º–∏–Ω | 24 —á–∞—Å–∞ | ‚ùå Manual Velero |

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ–ø–æ–≤–µ—â–µ–Ω–∏—è

### Grafana Dashboard –¥–ª—è Canary Deployments

```bash
# –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≥–æ—Ç–æ–≤—ã–π dashboard –¥–ª—è Argo Rollouts
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-rollouts
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  argo-rollouts.json: |
    {
      "dashboard": {
        "title": "Argo Rollouts - Canary Deployments",
        "panels": [
          {
            "title": "Rollout Status",
            "targets": [
              {
                "expr": "argo_rollouts_info{namespace='ezyshop'}"
              }
            ]
          },
          {
            "title": "Canary Weight",
            "targets": [
              {
                "expr": "argo_rollouts_canary_weight{namespace='ezyshop'}"
              }
            ]
          },
          {
            "title": "Success Rate (Canary vs Stable)",
            "targets": [
              {
                "expr": "sum(rate(http_requests_total{status=~'2..',namespace='ezyshop'}[5m])) / sum(rate(http_requests_total{namespace='ezyshop'}[5m]))"
              }
            ]
          }
        ]
      }
    }
EOF
```

### üÜï AlertManager Rules –¥–ª—è –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

```bash
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-alert-rules
  namespace: monitoring
data:
  alert-rules.yml: |
    groups:
    # üÜï Backup Alerts
    - name: backup-alerts
      interval: 5m
      rules:
      - alert: VeleroBackupFailed
        expr: velero_backup_failure_total > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Velero backup failed"
          description: "Velero backup {{ \$labels.schedule }} failed"
      
      - alert: PostgresBackupOld
        expr: time() - postgres_last_backup_timestamp > 14400
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "PostgreSQL backup is too old"
          description: "Last backup was more than 4 hours ago"
      
      - alert: BackupStorageFull
        expr: (1 - (node_filesystem_avail_bytes{mountpoint="/backups"} / node_filesystem_size_bytes{mountpoint="/backups"})) > 0.85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Backup storage is almost full"
          description: "Backup storage is {{ \$value | humanizePercentage }} full"
    
    # üÜï Security Alerts
    - name: security-alerts
      interval: 5m
      rules:
      - alert: HighCVEsDetected
        expr: trivy_image_vulnerabilities{severity="CRITICAL"} > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Critical CVEs detected in image"
          description: "Image {{ \$labels.image }} has {{ \$value }} CRITICAL vulnerabilities"
      
      - alert: VaultSealed
        expr: vault_core_unsealed == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Vault is sealed"
          description: "Vault instance is sealed and cannot serve requests"
      
      - alert: UnauthorizedAPIAccess
        expr: rate(apiserver_audit_event_total{verb="create",objectRef_resource="pods",user_username!~"system:.*"}[5m]) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Unusual API access pattern detected"
    
    # üÜï Deployment Alerts
    - name: deployment-alerts
      interval: 30s
      rules:
      - alert: CanaryDeploymentStuck
        expr: argo_rollouts_info{phase="Progressing"} and changes(argo_rollouts_info{phase="Progressing"}[15m]) == 0
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Canary deployment stuck"
          description: "Rollout {{ \$labels.name }} in {{ \$labels.namespace }} is stuck in Progressing phase"
      
      - alert: CanaryDeploymentFailed
        expr: argo_rollouts_info{phase="Degraded"}
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Canary deployment failed"
          description: "Rollout {{ \$labels.name }} in {{ \$labels.namespace }} has failed"
      
      - alert: RolloutAborted
        expr: argo_rollouts_info{phase="Aborted"}
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Rollout was aborted"
          description: "Rollout {{ \$labels.name }} in {{ \$labels.namespace }} was aborted"
    
    # Existing alerts
    - name: kubernetes-alerts
      interval: 30s
      rules:
      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Pod {{ \$labels.namespace }}/{{ \$labels.pod }} is crash looping"
      
      - alert: NodeNotReady
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Node {{ \$labels.node }} is not ready"
      
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on {{ \$labels.instance }}"
      
      - alert: HighCPUUsage
        expr: 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage on {{ \$labels.instance }}"
      
      - alert: DiskSpaceLow
        expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) > 0.85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk space low on {{ \$labels.instance }}"
EOF

# –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
kubectl -n monitoring rollout restart deployment prometheus-kube-prometheus-operator
```

### üÜï Slack Integration –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –∞–ª–µ—Ä—Ç–æ–≤

```bash
# –û–±–Ω–æ–≤–∏—Ç—å AlertManager config —Å Slack webhook
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-config
  namespace: monitoring
stringData:
  alertmanager.yaml: |
    global:
      resolve_timeout: 5m
      slack_api_url: 'YOUR_SLACK_WEBHOOK_URL_HERE'
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'default'
      routes:
      # Critical alerts ‚Üí Slack immediately
      - match:
          severity: critical
        receiver: 'slack-critical'
        continue: true
      
      # Security alerts ‚Üí Slack
      - match_re:
          alertname: '.*CVE.*|VaultSealed|UnauthorizedAPIAccess'
        receiver: 'slack-security'
        continue: true
      
      # Backup alerts ‚Üí Slack
      - match_re:
          alertname: 'VeleroBackupFailed|PostgresBackupOld'
        receiver: 'slack-backup'
        continue: true
    
    receivers:
    - name: 'default'
      slack_configs:
      - channel: '#alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
    
    - name: 'slack-critical'
      slack_configs:
      - channel: '#critical-alerts'
        title: 'üö® CRITICAL: {{ .GroupLabels.alertname }}'
        text: |
          *Summary:* {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
          *Description:* {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
          *Severity:* CRITICAL
        color: 'danger'
        send_resolved: true
    
    - name: 'slack-security'
      slack_configs:
      - channel: '#security-alerts'
        title: 'üîí SECURITY: {{ .GroupLabels.alertname }}'
        text: |
          *Summary:* {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
          *Description:* {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
        color: 'warning'
        send_resolved: true
    
    - name: 'slack-backup'
      slack_configs:
      - channel: '#backup-alerts'
        title: 'üíæ BACKUP: {{ .GroupLabels.alertname }}'
        text: |
          *Summary:* {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
          *Description:* {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
        color: 'warning'
        send_resolved: true
EOF

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å AlertManager
kubectl -n monitoring rollout restart statefulset alertmanager-prometheus-kube-prometheus-alertmanager
```

---

## üîß –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### üÜï Troubleshooting –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

#### Vault Issues

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ Vault
kubectl -n vault-system get pods
kubectl -n vault-system logs vault-0

# Vault sealed –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
kubectl -n vault-system exec -it vault-0 -- vault status

# –ï—Å–ª–∏ sealed, unseal –≤—Ä—É—á–Ω—É—é (–≤ production –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ auto-unseal)
kubectl -n vault-system exec -it vault-0 -- vault operator unseal

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ–∫—Ä–µ—Ç–æ–≤
kubectl -n vault-system exec -it vault-0 -- vault kv get secret/ezyshop/database

# –¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å pod
kubectl -n ezyshop logs <pod-name> -c vault-agent-init
```

#### Velero Backup Issues

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ Velero
kubectl -n velero get pods
velero backup get
velero backup describe <backup-name>

# –õ–æ–≥–∏ backup
velero backup logs <backup-name>

# –ü—Ä–æ–≤–µ—Ä–∫–∞ connection –∫ MinIO
kubectl -n velero logs deployment/velero

# –†—É—á–Ω–æ–π backup –¥–ª—è debugging
velero backup create debug-backup --include-namespaces ezyshop --wait

# –ü—Ä–æ–≤–µ—Ä–∫–∞ MinIO
curl http://minio.local.lab:9000/minio/health/live
```

#### Argo Rollouts Issues

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ Rollout
kubectl argo rollouts get rollout ezyshop-frontend -n ezyshop

# –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
kubectl argo rollouts status ezyshop-frontend -n ezyshop

# –õ–æ–≥–∏ controller
kubectl -n argo-rollouts logs deployment/argo-rollouts

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Analysis
kubectl -n ezyshop get analysisrun
kubectl -n ezyshop describe analysisrun <name>

# –ï—Å–ª–∏ Rollout –∑–∞—Å—Ç—Ä—è–ª
kubectl argo rollouts abort ezyshop-frontend -n ezyshop
kubectl argo rollouts retry ezyshop-frontend -n ezyshop

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç—Ä–∏–∫ Prometheus
kubectl -n ezyshop port-forward svc/prometheus-kube-prometheus-prometheus 9090:9090
# –û—Ç–∫—Ä—ã—Ç—å: http://localhost:9090
# Query: sum(rate(http_requests_total{namespace="ezyshop"}[5m]))
```

#### Trivy Scan Issues

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ Trivy –Ω–∞ Jenkins
ssh admin@jenkins.local.lab
trivy --version
trivy image --help

# –¢–µ—Å—Ç–æ–≤–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
trivy image nginx:latest --severity HIGH,CRITICAL

# –û–±–Ω–æ–≤–∏—Ç—å DB —Ç—Ä–∏vy
trivy image --download-db-only

# –û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞
trivy image --clear-cache

# Offline scanning (–µ—Å–ª–∏ –Ω–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞)
trivy image --offline-scan nginx:latest
```

#### Network Policy Issues

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ Network Policies
kubectl -n ezyshop get networkpolicies
kubectl -n ezyshop describe networkpolicy <name>

# –¢–µ—Å—Ç connectivity –º–µ–∂–¥—É –ø–æ–¥–∞–º–∏
kubectl run -n ezyshop test-pod --image=nicolaka/netshoot -it --rm -- /bin/bash

# –í–Ω—É—Ç—Ä–∏ test-pod:
# –¢–µ—Å—Ç DNS
nslookup kubernetes.default

# –¢–µ—Å—Ç connectivity –∫ backend
curl http://ezyshop-backend:8080/health

# –¢–µ—Å—Ç connectivity –∫ PostgreSQL
nc -zv postgres 5432

# –ï—Å–ª–∏ connection refused, –≤—Ä–µ–º–µ–Ω–Ω–æ —É–¥–∞–ª–∏—Ç—å NetworkPolicy –¥–ª—è debugging
kubectl -n ezyshop delete networkpolicy <name>
```

### –û–±—â–∏–µ –ø—Ä–æ–±–ª–µ–º—ã

#### Pod –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è

```bash
# –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
kubectl -n ezyshop describe pod <pod-name>
kubectl -n ezyshop logs <pod-name>
kubectl -n ezyshop logs <pod-name> --previous  # –õ–æ–≥–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞

# –ü—Ä–æ–≤–µ—Ä–∫–∞ events
kubectl -n ezyshop get events --sort-by='.lastTimestamp'

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
kubectl top nodes
kubectl top pods -n ezyshop
```

#### Ingress –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ Traefik
kubectl -n traefik get pods
kubectl -n traefik logs -l app.kubernetes.io/name=traefik --tail=100

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Ingress
kubectl -n ezyshop get ingress
kubectl -n ezyshop describe ingress <name>

# –¢–µ—Å—Ç LoadBalancer
kubectl -n traefik get svc
curl -v http://192.168.100.100

# –ü—Ä–æ–≤–µ—Ä–∫–∞ DNS
dig @192.168.100.53 ezyshop.local.lab +short
```

#### Storage Issues

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ Longhorn
kubectl -n longhorn-system get pods
kubectl -n longhorn-system get pvc
kubectl -n longhorn-system get pv

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ Longhorn UI
# http://longhorn.local.lab

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Å–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –Ω–∞ nodes
kubectl get nodes -o custom-columns=NAME:.metadata.name,DISK:.status.allocatable.ephemeral-storage
```

---

## üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### üÜï Resource Optimization

```bash
# –°–æ–∑–¥–∞—Ç—å VPA (Vertical Pod Autoscaler) –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
cat <<EOF | kubectl apply -f -
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: ezyshop-frontend-vpa
  namespace: ezyshop
spec:
  targetRef:
    apiVersion: argoproj.io/v1alpha1
    kind: Rollout
    name: ezyshop-frontend
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: frontend
      minAllowed:
        cpu: 50m
        memory: 64Mi
      maxAllowed:
        cpu: 1000m
        memory: 1Gi
EOF
```

### üÜï Cache Layer (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –±—É–¥—É—â–µ–≥–æ)

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Redis –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo update

cat > /tmp/redis-values.yaml <<EOF
architecture: standalone
auth:
  enabled: true
  password: redis-password-123

master:
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
  persistence:
    enabled: true
    storageClass: longhorn
    size: 8Gi

metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    namespace: monitoring
EOF

kubectl create namespace cache
helm install redis bitnami/redis \
    --namespace cache \
    --values /tmp/redis-values.yaml

# –í –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
# REDIS_HOST=redis-master.cache.svc.cluster.local
# REDIS_PORT=6379
# REDIS_PASSWORD=redis-password-123
```

---

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### Security Checklist v2.0

- ‚úÖ **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–∞–º–∏**: Vault —Å Kubernetes auth
- ‚úÖ **Image scanning**: Trivy –≤ CI pipeline
- ‚úÖ **Network isolation**: Network Policies –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
- ‚úÖ **RBAC**: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∞ –¥–ª—è ServiceAccounts
- ‚úÖ **TLS/SSL**: Cloudflare –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞
- ‚úÖ **Pod Security**: SecurityContext, PodDisruptionBudget
- ‚úÖ **Audit logging**: Kubernetes audit logs –≤ Elasticsearch
- ‚úÖ **Backup encryption**: Velero —Å encryption (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- ‚ö†Ô∏è **TODO**: Image signing (Cosign/Notary)
- ‚ö†Ô∏è **TODO**: Runtime security (Falco)
- ‚ö†Ô∏è **TODO**: WAF (ModSecurity)

### üÜï Security Best Practices

```bash
# 1. –†–µ–≥—É–ª—è—Ä–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –æ–±—Ä–∞–∑–æ–≤
for image in $(kubectl get pods -A -o jsonpath='{.items[*].spec.containers[*].image}' | tr ' ' '\n' | sort -u); do
  echo "Scanning: $image"
  trivy image --severity HIGH,CRITICAL $image
done

# 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö Kubernetes –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
kubectl version --short

# 3. –ê—É–¥–∏—Ç RBAC —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π
kubectl auth can-i --list --as=system:serviceaccount:ezyshop:ezyshop-sa -n ezyshop

# 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ–∫—Ä–µ—Ç–æ–≤ –≤ Git (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ —É—Ç–µ—á–µ–∫)
git secrets --scan --recursive

# 5. Rot–∞—Ü–∏—è —Å–µ–∫—Ä–µ—Ç–æ–≤ (–∫–∞–∂–¥—ã–µ 90 –¥–Ω–µ–π)
kubectl -n vault-system exec -it vault-0 -- vault kv put secret/ezyshop/database \
    username=ezyshop \
    password=$(openssl rand -base64 32)
```

---

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

```bash
# –°–ª–µ–¥–∏—Ç—å –∑–∞ –≤—Å–µ–º–∏ –ø–æ–¥–∞–º–∏
watch kubectl get pods -A

# –°–ª–µ–¥–∏—Ç—å –∑–∞ Rollout
watch kubectl argo rollouts get rollout ezyshop-frontend -n ezyshop

# –°–ª–µ–¥–∏—Ç—å –∑–∞ HPA
watch kubectl get hpa -A

# –°–ª–µ–¥–∏—Ç—å –∑–∞ —Ä–µ—Å—É—Ä—Å–∞–º–∏
watch kubectl top nodes
watch kubectl top pods -n ezyshop

# –°–ª–µ–¥–∏—Ç—å –∑–∞ backup
watch velero backup get

# –°–ª–µ–¥–∏—Ç—å –∑–∞ events
kubectl get events -A --watch
```

### –ë—ã—Å—Ç—Ä–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
echo "=== K3s Nodes ==="
kubectl get nodes

echo "=== Core Services ==="
kubectl get pods -n kube-system
kubectl get pods -n traefik
kubectl get pods -n metallb-system

echo "=== Monitoring ==="
kubectl get pods -n monitoring

echo "=== Security ==="
kubectl get pods -n vault-system

echo "=== Backup ==="
kubectl get pods -n velero

echo "=== Application ==="
kubectl get pods -n ezyshop
kubectl argo rollouts get rollout -n ezyshop

echo "=== Storage ==="
kubectl get pvc -A
kubectl get pv

echo "=== Ingress ==="
kubectl get ingress -A
```

---

## üìñ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–í—ã —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É–ª–∏ **Production-Ready DevOps –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É v2.0** —Å:

### ‚úÖ –ß—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å

1. **üîí Enterprise Security**
   - –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–∞–º–∏ (Vault)
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π (Trivy)
   - –°–µ—Ç–µ–≤–∞—è –∏–∑–æ–ª—è—Ü–∏—è (Network Policies)

2. **üíæ Disaster Recovery**
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ backup –∫–ª–∞—Å—Ç–µ—Ä–∞ (Velero)
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ backup –ë–î (PostgreSQL CronJob)
   - RTO < 30 –º–∏–Ω—É—Ç, RPO < 3 —á–∞—Å–∞

3. **üöÄ Progressive Delivery**
   - Canary deployments (Argo Rollouts)
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π rollback –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
   - Zero-downtime deployments

4. **üìä Observability**
   - –ü–æ–ª–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (Prometheus + Grafana)
   - –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (ELK)
   - Real-time –∞–ª–µ—Ä—Ç—ã (Slack)

### üéØ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

1. **Service Mesh** (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è)
   ```bash
   # Linkerd (–±–æ–ª–µ–µ –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π —á–µ–º Istio)
   curl -sL https://run.linkerd.io/install | sh
   linkerd install | kubectl apply -f -
   ```

2. **Distributed Tracing** (–¥–ª—è debugging –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤)
   ```bash
   # Jaeger
   helm install jaeger jaegertracing/jaeger
   ```

3. **GitOps –¥–ª—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã** (Infrastructure as Code)
   ```bash
   # Flux CD –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è Helm releases
   flux bootstrap github --owner=yourname --repository=k8s-infra
   ```

---

## üÜò –ü–æ–¥–¥–µ—Ä–∂–∫–∞

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- Kubernetes: https://kubernetes.io/docs/
- K3s: https://docs.k3s.io/
- ArgoCD: https://argo-cd.readthedocs.io/
- Argo Rollouts: https://argoproj.github.io/argo-rollouts/
- Velero: https://velero.io/docs/
- Vault: https://www.vaultproject.io/docs/
- Trivy: https://aquasecurity.github.io/trivy/

### –õ–∏—Ü–µ–Ω–∑–∏—è
MIT License

---

**–í–µ—Ä—Å–∏—è**: 2.0.0  
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: –û–∫—Ç—è–±—Ä—å 2024  
**–ê–≤—Ç–æ—Ä**: DevOps Team  

üéâ **–ü–æ–∑–¥—Ä–∞–≤–ª—è–µ–º! –í–∞—à–∞ production-ready –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≥–æ—Ç–æ–≤–∞!**